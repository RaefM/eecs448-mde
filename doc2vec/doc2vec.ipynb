{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%config Completer.use_jedi = False\n",
    "%autoreload 2\n",
    "from doc2vec import *\n",
    "from preprocess import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models.doc2vec import TaggedDocument, Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = pd.read_csv('aita_preprocessed_new.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = base_df[['processed_body', 'id']]\n",
    "y = base_df.is_asshole.values\n",
    "X_train, _, _, _ = train_test_split(X, y, test_size=0.2, random_state=448, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tagged_doc(post): return TaggedDocument(word_tokenize(post['processed_body']), post['id'])\n",
    "data_training = X_train.apply(to_tagged_doc, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_training\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvec_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/class/448/mde/doc2vec/doc2vec.py:15\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(data_training, vec_size, num_threads)\u001b[0m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m Doc2Vec(\n\u001b[1;32m      8\u001b[0m     vector_size\u001b[38;5;241m=\u001b[39mvec_size, \n\u001b[1;32m      9\u001b[0m     workers\u001b[38;5;241m=\u001b[39mnum_threads,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m448\u001b[39m\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mbuild_vocab(data_training)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_training\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorpus_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/class/448/eecs448/lib/python3.8/site-packages/gensim/models/doc2vec.py:516\u001b[0m, in \u001b[0;36mDoc2Vec.train\u001b[0;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    513\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moffsets\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m offsets\n\u001b[1;32m    514\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_doctags\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m start_doctags\n\u001b[0;32m--> 516\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDoc2Vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcorpus_iterable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_iterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_examples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_alpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_alpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mword_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqueue_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqueue_factor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreport_delay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreport_delay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/class/448/eecs448/lib/python3.8/site-packages/gensim/models/word2vec.py:1073\u001b[0m, in \u001b[0;36mWord2Vec.train\u001b[0;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1070\u001b[0m     callback\u001b[38;5;241m.\u001b[39mon_epoch_begin(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m corpus_iterable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1073\u001b[0m     trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcorpus_iterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcur_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_examples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqueue_factor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreport_delay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreport_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1078\u001b[0m     trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_epoch_corpusfile(\n\u001b[1;32m   1079\u001b[0m         corpus_file, cur_epoch\u001b[38;5;241m=\u001b[39mcur_epoch, total_examples\u001b[38;5;241m=\u001b[39mtotal_examples, total_words\u001b[38;5;241m=\u001b[39mtotal_words,\n\u001b[1;32m   1080\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/class/448/eecs448/lib/python3.8/site-packages/gensim/models/word2vec.py:1434\u001b[0m, in \u001b[0;36mWord2Vec._train_epoch\u001b[0;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay, callbacks)\u001b[0m\n\u001b[1;32m   1431\u001b[0m     thread\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# make interrupting the process with ctrl+c easier\u001b[39;00m\n\u001b[1;32m   1432\u001b[0m     thread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m-> 1434\u001b[0m trained_word_count, raw_word_count, job_tally \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_epoch_progress\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1435\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_queue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_queue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcur_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_examples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1436\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreport_delay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreport_delay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_corpus_file_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1437\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1439\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trained_word_count, raw_word_count, job_tally\n",
      "File \u001b[0;32m~/class/448/eecs448/lib/python3.8/site-packages/gensim/models/word2vec.py:1289\u001b[0m, in \u001b[0;36mWord2Vec._log_epoch_progress\u001b[0;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[1;32m   1286\u001b[0m unfinished_worker_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m unfinished_worker_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1289\u001b[0m     report \u001b[38;5;241m=\u001b[39m \u001b[43mprogress_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# blocks if workers too slow\u001b[39;00m\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m report \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# a thread reporting that it finished\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m         unfinished_worker_count \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3.8/queue.py:170\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qsize():\n\u001b[0;32m--> 170\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a non-negative number\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = train_model(data_training, vec_size=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = infer_all_vecs(model, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dim 0</th>\n",
       "      <th>Dim 1</th>\n",
       "      <th>Dim 2</th>\n",
       "      <th>Dim 3</th>\n",
       "      <th>Dim 4</th>\n",
       "      <th>Dim 5</th>\n",
       "      <th>Dim 6</th>\n",
       "      <th>Dim 7</th>\n",
       "      <th>Dim 8</th>\n",
       "      <th>Dim 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Dim 291</th>\n",
       "      <th>Dim 292</th>\n",
       "      <th>Dim 293</th>\n",
       "      <th>Dim 294</th>\n",
       "      <th>Dim 295</th>\n",
       "      <th>Dim 296</th>\n",
       "      <th>Dim 297</th>\n",
       "      <th>Dim 298</th>\n",
       "      <th>Dim 299</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.178887</td>\n",
       "      <td>-0.170738</td>\n",
       "      <td>-0.010803</td>\n",
       "      <td>0.177611</td>\n",
       "      <td>0.087199</td>\n",
       "      <td>-1.191950</td>\n",
       "      <td>0.504145</td>\n",
       "      <td>0.055026</td>\n",
       "      <td>-0.404128</td>\n",
       "      <td>0.264374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154847</td>\n",
       "      <td>0.056020</td>\n",
       "      <td>-0.654372</td>\n",
       "      <td>0.473542</td>\n",
       "      <td>0.457792</td>\n",
       "      <td>0.674619</td>\n",
       "      <td>0.419598</td>\n",
       "      <td>0.032041</td>\n",
       "      <td>-0.792138</td>\n",
       "      <td>1ytxov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.251109</td>\n",
       "      <td>-0.072320</td>\n",
       "      <td>-0.239009</td>\n",
       "      <td>1.113421</td>\n",
       "      <td>-0.021707</td>\n",
       "      <td>-1.200141</td>\n",
       "      <td>0.238938</td>\n",
       "      <td>0.397736</td>\n",
       "      <td>-0.228495</td>\n",
       "      <td>1.420341</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083705</td>\n",
       "      <td>0.423500</td>\n",
       "      <td>-0.344016</td>\n",
       "      <td>0.439633</td>\n",
       "      <td>0.646533</td>\n",
       "      <td>0.317631</td>\n",
       "      <td>0.371013</td>\n",
       "      <td>0.394109</td>\n",
       "      <td>-0.118583</td>\n",
       "      <td>1yu29c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.028897</td>\n",
       "      <td>-0.056972</td>\n",
       "      <td>-0.067148</td>\n",
       "      <td>0.154962</td>\n",
       "      <td>-0.025976</td>\n",
       "      <td>-0.299833</td>\n",
       "      <td>0.188303</td>\n",
       "      <td>0.104384</td>\n",
       "      <td>0.165461</td>\n",
       "      <td>0.202716</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034777</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>-0.087872</td>\n",
       "      <td>-0.056354</td>\n",
       "      <td>0.181080</td>\n",
       "      <td>0.085898</td>\n",
       "      <td>0.122283</td>\n",
       "      <td>0.058977</td>\n",
       "      <td>-0.278042</td>\n",
       "      <td>1yu8hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.098481</td>\n",
       "      <td>0.090423</td>\n",
       "      <td>-0.195897</td>\n",
       "      <td>0.350061</td>\n",
       "      <td>-0.011176</td>\n",
       "      <td>-0.618214</td>\n",
       "      <td>0.324383</td>\n",
       "      <td>0.010868</td>\n",
       "      <td>-0.008799</td>\n",
       "      <td>0.334736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052374</td>\n",
       "      <td>-0.122489</td>\n",
       "      <td>-0.230916</td>\n",
       "      <td>0.153518</td>\n",
       "      <td>0.171373</td>\n",
       "      <td>-0.024541</td>\n",
       "      <td>0.177481</td>\n",
       "      <td>0.115768</td>\n",
       "      <td>-0.270568</td>\n",
       "      <td>1yuc78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.037975</td>\n",
       "      <td>0.070058</td>\n",
       "      <td>0.212931</td>\n",
       "      <td>0.128882</td>\n",
       "      <td>0.107916</td>\n",
       "      <td>-0.450925</td>\n",
       "      <td>0.335366</td>\n",
       "      <td>-0.012343</td>\n",
       "      <td>0.105978</td>\n",
       "      <td>-0.047050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386428</td>\n",
       "      <td>0.149711</td>\n",
       "      <td>-0.184223</td>\n",
       "      <td>0.115063</td>\n",
       "      <td>0.212872</td>\n",
       "      <td>0.481097</td>\n",
       "      <td>0.128577</td>\n",
       "      <td>-0.292639</td>\n",
       "      <td>-0.637323</td>\n",
       "      <td>1yueqb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97623</th>\n",
       "      <td>0.544422</td>\n",
       "      <td>0.382126</td>\n",
       "      <td>0.077862</td>\n",
       "      <td>1.141482</td>\n",
       "      <td>-0.128622</td>\n",
       "      <td>-1.046654</td>\n",
       "      <td>0.967444</td>\n",
       "      <td>0.361653</td>\n",
       "      <td>-0.200008</td>\n",
       "      <td>1.043416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005996</td>\n",
       "      <td>0.089267</td>\n",
       "      <td>-0.292380</td>\n",
       "      <td>-0.089731</td>\n",
       "      <td>0.655906</td>\n",
       "      <td>0.407875</td>\n",
       "      <td>0.098423</td>\n",
       "      <td>0.244114</td>\n",
       "      <td>-0.760525</td>\n",
       "      <td>ex94w5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97624</th>\n",
       "      <td>0.616415</td>\n",
       "      <td>0.267349</td>\n",
       "      <td>-0.367084</td>\n",
       "      <td>0.462266</td>\n",
       "      <td>-0.435591</td>\n",
       "      <td>-1.891354</td>\n",
       "      <td>0.668876</td>\n",
       "      <td>-0.080783</td>\n",
       "      <td>-0.331416</td>\n",
       "      <td>0.964102</td>\n",
       "      <td>...</td>\n",
       "      <td>1.478724</td>\n",
       "      <td>-0.389029</td>\n",
       "      <td>-0.266751</td>\n",
       "      <td>0.388264</td>\n",
       "      <td>-0.101122</td>\n",
       "      <td>-0.413777</td>\n",
       "      <td>0.526668</td>\n",
       "      <td>0.316098</td>\n",
       "      <td>-0.278589</td>\n",
       "      <td>ex970f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97625</th>\n",
       "      <td>0.834846</td>\n",
       "      <td>-0.610160</td>\n",
       "      <td>-1.028050</td>\n",
       "      <td>1.456335</td>\n",
       "      <td>1.097802</td>\n",
       "      <td>-1.007389</td>\n",
       "      <td>0.769968</td>\n",
       "      <td>0.078018</td>\n",
       "      <td>-1.264583</td>\n",
       "      <td>0.573329</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.528305</td>\n",
       "      <td>-0.217637</td>\n",
       "      <td>-0.511219</td>\n",
       "      <td>0.917292</td>\n",
       "      <td>0.165847</td>\n",
       "      <td>-0.543156</td>\n",
       "      <td>0.016791</td>\n",
       "      <td>0.982262</td>\n",
       "      <td>-1.139684</td>\n",
       "      <td>ex9dwo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97626</th>\n",
       "      <td>-0.375068</td>\n",
       "      <td>0.036265</td>\n",
       "      <td>-0.467868</td>\n",
       "      <td>0.806717</td>\n",
       "      <td>-0.762043</td>\n",
       "      <td>-1.873656</td>\n",
       "      <td>1.005097</td>\n",
       "      <td>0.627478</td>\n",
       "      <td>0.151553</td>\n",
       "      <td>-0.063979</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.339165</td>\n",
       "      <td>0.223894</td>\n",
       "      <td>-0.058020</td>\n",
       "      <td>0.192320</td>\n",
       "      <td>1.537907</td>\n",
       "      <td>0.540814</td>\n",
       "      <td>-0.131951</td>\n",
       "      <td>0.325501</td>\n",
       "      <td>-0.142700</td>\n",
       "      <td>ex9egs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97627</th>\n",
       "      <td>-0.099090</td>\n",
       "      <td>-0.502863</td>\n",
       "      <td>-0.881684</td>\n",
       "      <td>1.215147</td>\n",
       "      <td>0.417412</td>\n",
       "      <td>-1.060823</td>\n",
       "      <td>0.505935</td>\n",
       "      <td>-0.848400</td>\n",
       "      <td>-0.550706</td>\n",
       "      <td>0.396701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175271</td>\n",
       "      <td>0.298654</td>\n",
       "      <td>0.698345</td>\n",
       "      <td>0.289030</td>\n",
       "      <td>0.548522</td>\n",
       "      <td>-0.748359</td>\n",
       "      <td>1.096391</td>\n",
       "      <td>-1.352803</td>\n",
       "      <td>-1.165255</td>\n",
       "      <td>ex9g78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97628 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Dim 0     Dim 1     Dim 2     Dim 3     Dim 4     Dim 5     Dim 6  \\\n",
       "0      0.178887 -0.170738 -0.010803  0.177611  0.087199 -1.191950  0.504145   \n",
       "1      0.251109 -0.072320 -0.239009  1.113421 -0.021707 -1.200141  0.238938   \n",
       "2     -0.028897 -0.056972 -0.067148  0.154962 -0.025976 -0.299833  0.188303   \n",
       "3      0.098481  0.090423 -0.195897  0.350061 -0.011176 -0.618214  0.324383   \n",
       "4     -0.037975  0.070058  0.212931  0.128882  0.107916 -0.450925  0.335366   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "97623  0.544422  0.382126  0.077862  1.141482 -0.128622 -1.046654  0.967444   \n",
       "97624  0.616415  0.267349 -0.367084  0.462266 -0.435591 -1.891354  0.668876   \n",
       "97625  0.834846 -0.610160 -1.028050  1.456335  1.097802 -1.007389  0.769968   \n",
       "97626 -0.375068  0.036265 -0.467868  0.806717 -0.762043 -1.873656  1.005097   \n",
       "97627 -0.099090 -0.502863 -0.881684  1.215147  0.417412 -1.060823  0.505935   \n",
       "\n",
       "          Dim 7     Dim 8     Dim 9  ...   Dim 291   Dim 292   Dim 293  \\\n",
       "0      0.055026 -0.404128  0.264374  ...  0.154847  0.056020 -0.654372   \n",
       "1      0.397736 -0.228495  1.420341  ... -0.083705  0.423500 -0.344016   \n",
       "2      0.104384  0.165461  0.202716  ... -0.034777  0.025981 -0.087872   \n",
       "3      0.010868 -0.008799  0.334736  ...  0.052374 -0.122489 -0.230916   \n",
       "4     -0.012343  0.105978 -0.047050  ...  0.386428  0.149711 -0.184223   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "97623  0.361653 -0.200008  1.043416  ...  0.005996  0.089267 -0.292380   \n",
       "97624 -0.080783 -0.331416  0.964102  ...  1.478724 -0.389029 -0.266751   \n",
       "97625  0.078018 -1.264583  0.573329  ... -0.528305 -0.217637 -0.511219   \n",
       "97626  0.627478  0.151553 -0.063979  ... -0.339165  0.223894 -0.058020   \n",
       "97627 -0.848400 -0.550706  0.396701  ...  0.175271  0.298654  0.698345   \n",
       "\n",
       "        Dim 294   Dim 295   Dim 296   Dim 297   Dim 298   Dim 299      id  \n",
       "0      0.473542  0.457792  0.674619  0.419598  0.032041 -0.792138  1ytxov  \n",
       "1      0.439633  0.646533  0.317631  0.371013  0.394109 -0.118583  1yu29c  \n",
       "2     -0.056354  0.181080  0.085898  0.122283  0.058977 -0.278042  1yu8hi  \n",
       "3      0.153518  0.171373 -0.024541  0.177481  0.115768 -0.270568  1yuc78  \n",
       "4      0.115063  0.212872  0.481097  0.128577 -0.292639 -0.637323  1yueqb  \n",
       "...         ...       ...       ...       ...       ...       ...     ...  \n",
       "97623 -0.089731  0.655906  0.407875  0.098423  0.244114 -0.760525  ex94w5  \n",
       "97624  0.388264 -0.101122 -0.413777  0.526668  0.316098 -0.278589  ex970f  \n",
       "97625  0.917292  0.165847 -0.543156  0.016791  0.982262 -1.139684  ex9dwo  \n",
       "97626  0.192320  1.537907  0.540814 -0.131951  0.325501 -0.142700  ex9egs  \n",
       "97627  0.289030  0.548522 -0.748359  1.096391 -1.352803 -1.165255  ex9g78  \n",
       "\n",
       "[97628 rows x 301 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vec_df, word_to_embedding = construct_d2v_df(model, vecs, X)\n",
    "doc2vec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_df.to_csv('aita_doc2vec.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('aita_doc2vec_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to instantiate the trained model:\n",
    "#dvmodelcopy = Doc2Vec.load('aita_doc2vec_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
