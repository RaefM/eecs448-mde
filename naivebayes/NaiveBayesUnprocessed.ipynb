{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16628480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pickle\n",
    "import scipy.sparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.naive_bayes import ComplementNB, GaussianNB, MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19531bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "aita_raw_df = pd.read_csv('aita_minimal_preprocess.csv', usecols=[ \"post\", \"is_asshole\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "670e00a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AITA for wanting to dump a girl after finding out she has an STD?So I (32m) started dating a new girl (26f) after a disgusting horrible divorce from my wife who I’ve been with for like 15 years.. \n",
      "\n",
      "So I was super patent and deliberate in choosing a girl to date, turning down lots of others over the last year or so of separation... Then I met this girl and she is like EVERYTHING I want in a woman, and I could really see myself having a long-term relationship with her. \n",
      "\n",
      "We took things slow and waited about a month to have sex, just fooling around and doing other stuff. Then when the time came she stopped me right before and told me she had been living with herpes since the age of 19.. She was very mature and responsible and understanding and said she’d give me time to think about it, but...TBH I’m fucking freaking out. I’m terrified that this could affect me and my life forever if I end up being with her.\n",
      "\n",
      "I basically told her all of this, and broke up with her. I said that I couldn’t risk my health or well being and that I’ve been through too much to not give myself every chance at happiness. She says I’m being immature and I’m an asshole and insists that it’s really no big deal.\n",
      "\n",
      "So, am I being an asshole?? I sure feel like one... But at this point in my life and with a daughter who I basically raise alone I need to be selfish with my time and my life. Has anyone been in a similar situation? What are my options? Help me out Reddit, I’m feeling pretty f’ed up over this...\n",
      "0\n",
      "62481\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    aita_raw_df.post.values, \n",
    "    aita_raw_df.is_asshole.values,\n",
    "    stratify = aita_raw_df.is_asshole.values,\n",
    "    test_size = 0.2, \n",
    "    random_state = 448\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    stratify = y_train,\n",
    "    test_size = 0.2, \n",
    "    random_state = 448\n",
    ")\n",
    "print(X_train[0])\n",
    "print(y_train[0])\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a4c73f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min df of 0.001, Max df of 0.6, Max Ngram 3 had UAR 0.5976658285014219\n",
      "Min df of 0.001, Max df of 0.6, Max Ngram 4 had UAR 0.5971741537831234\n",
      "Min df of 0.001, Max df of 0.7, Max Ngram 3 had UAR 0.5985746280929174\n",
      "Min df of 0.001, Max df of 0.7, Max Ngram 4 had UAR 0.595008572455302\n",
      "Min df of 0.001, Max df of 0.8, Max Ngram 3 had UAR 0.59780952107489\n",
      "Min df of 0.001, Max df of 0.8, Max Ngram 4 had UAR 0.5943613343670249\n",
      "Min df of 0.005, Max df of 0.6, Max Ngram 3 had UAR 0.5898002449486032\n",
      "Min df of 0.005, Max df of 0.6, Max Ngram 4 had UAR 0.5887714943766607\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 10\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ngram_ceil \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]:\n\u001b[1;32m      4\u001b[0m     vectorizer \u001b[38;5;241m=\u001b[39m CountVectorizer(\n\u001b[1;32m      5\u001b[0m         lowercase\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m      6\u001b[0m         min_df\u001b[38;5;241m=\u001b[39mmin_df, \n\u001b[1;32m      7\u001b[0m         max_df\u001b[38;5;241m=\u001b[39mmax_df, \n\u001b[1;32m      8\u001b[0m         ngram_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,ngram_ceil)\n\u001b[1;32m      9\u001b[0m     )\n\u001b[0;32m---> 10\u001b[0m     X_train_counts \u001b[38;5;241m=\u001b[39m \u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     X_val_counts \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mtransform(X_val)\n\u001b[1;32m     12\u001b[0m     clf_comp \u001b[38;5;241m=\u001b[39m ComplementNB(alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n",
      "File \u001b[0;32m~/class/448/eecs448/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:1377\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1369\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1370\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1371\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1372\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1373\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1374\u001b[0m             )\n\u001b[1;32m   1375\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1377\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[1;32m   1380\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/class/448/eecs448/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:1266\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m analyze(doc):\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1266\u001b[0m         feature_idx \u001b[38;5;241m=\u001b[39m \u001b[43mvocabulary\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1267\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m feature_idx \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m feature_counter:\n\u001b[1;32m   1268\u001b[0m             feature_counter[feature_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for min_df in [0.001, 0.005, 0.01]:\n",
    "    for max_df in [0.6, 0.7, 0.8]: \n",
    "        for ngram_ceil in [3, 4]:\n",
    "            vectorizer = CountVectorizer(\n",
    "                lowercase=True, \n",
    "                min_df=min_df, \n",
    "                max_df=max_df, \n",
    "                ngram_range=(1,ngram_ceil)\n",
    "            )\n",
    "            X_train_counts = vectorizer.fit_transform(X_train)\n",
    "            X_val_counts = vectorizer.transform(X_val)\n",
    "            clf_comp = ComplementNB(alpha=1e-5)\n",
    "            clf_comp.fit(X_train_counts, y_train)\n",
    "            y_pred_comp = clf_comp.predict(X_val_counts)\n",
    "            val_score = balanced_accuracy_score(y_val, y_pred_comp)\n",
    "            print(f\"Min df of {min_df}, Max df of {max_df}, Max Ngram {ngram_ceil} had UAR {val_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "03a7833d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set UAR: 0.5905575193095205\n"
     ]
    }
   ],
   "source": [
    "best_min_df, best_max_df, best_ceil = 0.001, 0.7, 3\n",
    "vectorizer = CountVectorizer(\n",
    "    lowercase=True, \n",
    "    min_df=best_min_df, \n",
    "    max_df=best_max_df, \n",
    "    ngram_range=(1,best_ceil)\n",
    ")\n",
    "X_train_counts = vectorizer.fit_transform(X_train)\n",
    "X_test_counts = vectorizer.transform(X_test)\n",
    "clf_comp = ComplementNB(alpha=1e-5)\n",
    "clf_comp.fit(X_train_counts, y_train)\n",
    "y_pred_comp = clf_comp.predict(X_test_counts)\n",
    "test_score = balanced_accuracy_score(y_test, y_pred_comp)\n",
    "print(f\"Test set UAR: {test_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
